# Next Steps
### Jill Bennett (Data Science)

- Researching how differing sets of training data effect the outcome (ex. changing genre, specific artists, etc.)
- In general, finding a way for us to predict/direct some qualities of the outputted songs
- Looking into creating a larger database of images/songs to work with
- Better results through looking at album artwork vs. single artwork (might have stronger correlation between songs released as a single, than just songs pulled from a full-length album)
- Researching how using different sizes/resolution of images effect the songs
- Researching how different lengths of songs effect the outcome of the generated music
- Would analyzing images using object identification as well as point-of-interest identifiction increase the correlation between songs and images?

*Personal Goals:*
- Understanding on a deeper level the code actually involved in making the LSTM (how it works)
- Being able to apply the general framework of this project to other situations


### Joey Tepperman (Project Manager)

We have done some really cool stuff this year and I am really proud of everything the team has accomplished. That being said, we now have a great foundation for exploring new things and improving existing aspects of the project. Here is a summary:

- **Diving deeper into neural networks**

We have a functioning neural network and a good baseline understanding of how it works. However, there is room for improvement in understanding what's actually going on in the individual layers of the neural net.

- **Experiment with different models**

It would be cool to try out a few different models and seeing which performs best. It would also be cool to try some models more closely related to the [original](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5?gi=26f1e5833f85) that compare sequences of notes with following ones.

- **Transfer Learning**

It would be cool to experiment with transfer learning and see how we can use it in this context!

