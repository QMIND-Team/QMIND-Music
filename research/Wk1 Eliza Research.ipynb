{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  RNNs with better memory\n",
    "-  improves “vanishing gradient” issues\n",
    "-  the units of an LSTM are used as building units for the layers of a RNN (time component)\n",
    "-  LSTM can read, write and delete information from its memory\n",
    "-  only stores information the algorithm deems important\n",
    "-  the algorithm learns over time which information is important and which not\n",
    "-  input gate:whether or not to let new input in \n",
    "-  forget gate: delete the information because it isn’t important \n",
    "-  output gate: to let it impact the output at the current time step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  when making decisions it considers current input and whatever it learned from previous inputs\n",
    "-  internal memory\n",
    "-  produces output, copies that output and loops it back into the network (see diagram)\n",
    "-  can map (input to output),  one to one, one to many, many to many, many to one\n",
    "-  inputs:present and recent past (both weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backword Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  adjust values/weights while training to improve accuracy\n",
    "-  OR “going backwards through your neural network to find the partial derivatives of the error with respect to the weights, which enables you to subtract this value from the weight”\n",
    "-  behind the scenes in the code but good to know for errors \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  an algorithm that is used to iteratively minimize a given function\n",
    "-  it adjusts the weights up or down, depending on which decreases the error\n",
    "-  how it learns during training\n",
    "-  gradient descent error found in RNNs is decreased in LSTMS bc they have better memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"nn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
