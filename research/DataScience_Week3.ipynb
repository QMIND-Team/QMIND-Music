{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Week 3:\n",
    "Jill Bennett, January 28, 2019\n",
    "\n",
    "Make a csv with ~100 various songs, store their track id, preview url, and multiple image urls in the columns. Don't take multiple songs from one album. Build a folder with all small images saved as jpgs, a folder with all previews saved as mp3s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_name\n",
      "one     u2\n",
      "Name: album, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from spotify_api_client import get, search, search_all\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#open the csv that I have created as a dataframe\n",
    "#index_col = 'song_name' ?\n",
    "#df = pd.read_csv('songData.csv', header = 0, names = ['song_name', 'album', 'id', 'small', 'med', 'large', 'preview'])\n",
    "#print(df.loc[:,'album'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function accesses a spotify playlist, retrieves track information, and adds it to the csv\n",
    "def get_100_songs(playlist):\n",
    "    rows_list = []\n",
    "    playlist_id = search(playlist, 'playlist') #returns id of first search result in a string\n",
    "    \n",
    "    offset = 0 #'offset' will propogate through lists of 100 tracks\n",
    "    \n",
    "    #specify where the files should be placed\n",
    "    preview_loc = '/Users/Jill/Documents/QMIND_Music_jpnb/song_preview_clips/'\n",
    "    image_loc = '/Users/Jill/Documents/QMIND_Music_jpnb/small_album_images/'\n",
    "    csv_loc = '/Users/Jill/Documents/QMIND_Music_jpnb/'\n",
    "    \n",
    "    while len(rows_list) < 100:\n",
    "    \n",
    "        playlist_data = get(f'v1/playlists/{playlist_id}/tracks?offset={offset}') #returns giant dictionary of playlist track features\n",
    "        num_songs_pl = len(playlist_data['items'])\n",
    "    \n",
    "        n = 0 #'n' will propagate through all songs in the playlist\n",
    "    \n",
    "        while n < 100: #loop over every song in the 'items' array\n",
    "        \n",
    "        if len(rows_list) >= 100: #we only need 100 songs\n",
    "            break\n",
    "
    "            #get the necessary data from the songs' info\n",
    "            track_id = playlist_data['items'][n]['track']['id']\n",
    "            small_image_url = playlist_data['items'][n]['track']['album']['images'][2]['url']\n",
    "            medium_image_url = playlist_data['items'][n]['track']['album']['images'][1]['url']\n",
    "            large_image_url = playlist_data['items'][n]['track']['album']['images'][0]['url']\n",
    "            preview_url = playlist_data['items'][n]['track']['preview_url']\n",
    "            track_name = playlist_data['items'][n]['track']['name']\n",
    "            album_name = playlist_data['items'][n]['track']['album']['name']\n",
    "        \n",
    "            #store the data in a dictionary\n",
    "            new_row = {'song_name': track_name, 'album': album_name, \n",
    "                       'id': track_id, 'small': small_image_url, 'med': medium_image_url, \n",
    "                       'large': large_image_url, 'preview': preview_url}\n",
    "        \n",
    "            proceed = True #keep track of state of procedure\n",
    "        \n",
    "            if preview_url != None: #check if a preview is available\n",
    "            \n",
    "                for row in rows_list: #check if the album has already been used\n",
    "                    if album_name == row['album']:\n",
    "                        proceed = False #don't add this song to the dataframe if this album is already used\n",
    "            \n",
    "                if proceed == True:\n",
    "                    #if new album, add this data to a new row in the list that will become the csv\n",
    "                    rows_list.append(new_row)\n",
    "                \n",
    "                    #also download the files to the folders\n",
    "                    r = requests.get(str(preview_url), allow_redirects=True)\n",
    "                    open(f'{preview_loc}{track_id}_preview.mp3', 'wb').write(r.content)\n",
    "                    s = requests.get(str(small_image_url), allow_redirects=True)\n",
    "                    open(f'{image_loc}{track_id}_art.jpg', 'wb').write(s.content)\n",
    "    \n",
    "            n += 1\n",
    "        offset += 100\n",
    "    \n",
    "    print(f'loop broken, rows = {len(rows_list)}')\n",
    "    \n",
    "    #finally, create a csv from the finish row of lists and export it\n",
    "    df = pd.DataFrame(rows_list)\n",
    "    #print(df)\n",
    "    #export the data to the csv\n",
    "    export_csv = df.to_csv (f'{csv_loc}tracks_csv.csv', index = None, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop broken at offset = 300 and rows = 133\n"
     ]
    }
   ],
   "source": [
    "test_playlist = 'best songs of all time 1950-2014' \n",
    "#can't go wrong with this playlist\n",
    "#has AC/DC and celine dion on same playlist\n",
    "get_100_songs(test_playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
