{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How is the music generated?\n",
    "\n",
    "The neural network generates a sequence of notes and chords. These notes are be played at even intervals, with 500 notes constituting a 2-minute song.\n",
    "\n",
    "The sequence is created by beginning with 5 arbitrary notes.\n",
    "A neural network will take this sequence as its input, and predict the 6th note that is the \"most probable\" to appear.\n",
    "The new sequence of 6 notes is then passed through the network as the input, generating a 7th note as the output.\n",
    "This is repeated until the sequence is 500 notes long.\n",
    "\n",
    "*the first 5 notes are removed from the sequence, so that the song is entirely generated by the outputs of the neural network.\n",
    "\n",
    "**How is the \"most probable\" next note chosen?\n",
    "\n",
    "The \"most probable\" next note is based on patterns detected in the songs used for training the network.\n",
    "For example: assume most songs in the training data have a G chord followed by a C chord. If a G occurs in the song being generated, then the \"most likely\" next note, will probably be a C chord.\n",
    "This is also applicable for longer patterns. If A-B-C is a common pattern in the training data, then the sequence of A-B will probably be followed with a C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How is this applicable to our project?\n",
    "\n",
    "An image will be analyzed, and a song will be generated to accompany the image. Images can be analyzed by converting them to an array of the pixel colours, using each colour's *hex code*. The process is shown below:\n",
    "\n",
    "    Image -->[convert to RGB pixels]--> 2D (or 3D) list -->[song generator]--> song\n",
    "\n",
    "Ideally, the song created from the music will have the same \"mood\". That is to say they both evoke a similar emotional response.\n",
    "*For example:* a dark, gloomy photo should generate a song with more minor chords and dissonance. On the other hand, a photo of blue skies and balloons would have a happier tone, and should match that with more major chords.\n",
    "\n",
    "**So how does the music generator create a song of a chosen mood?\n",
    "\n",
    "The music that is generated will follow the patterns detected in the training data. Ideally these patterns would also convey similar emotions, based on the frequency of certain chords and the chord/note progressions.\n",
    "For example, minor chords typically make a song sound sad. There are also chord progressions that are very effective at portraying different emotions and intensities.\n",
    "\n",
    "Using different input notes (the first 5-note sequence) could also provide variance, though it is harder to predict how this will affect the whole song.\n",
    "\n",
    "As the image analyst, I will organize the data from the images such that it can be easily used by the audio processor.\n",
    "Colour scheme and content are the two main elements that affect the mood of an image. Between these two characteristics, colour scheme requires much less code to analyze, since the hex codes contain all the data required.\n",
    "Some helpful characteristics will be the colour itself, how many different colours, and how \"light\" each shade is.\n",
    "Often dark monotones are less cheerful than bright primary colours, so this can be translated into the music generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why use an LSTM?\n",
    "\n",
    "LSTM stands for *long short-term memory*. LSTMs are used for predicting the next element of a sequence. In this case, a sequence of notes. When finding patterns in sequences, the network needs a memory of what occurred in the rest of the sequence, and in what order.\n",
    "\n",
    "LSTMs use multiple neural networks to make their prediction for the next element of the sequence.\n",
    "The networks predict likely elements to come next in the sequence, select data that is important to remember for future passes, and select data to ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural networks CAN create music!\n"
     ]
    }
   ],
   "source": [
    "print(\"neural networks CAN create music!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
